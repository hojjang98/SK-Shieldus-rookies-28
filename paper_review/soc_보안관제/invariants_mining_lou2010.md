# SOC (보안관제) — 논문 리뷰

이 폴더는 **보안관제(Security Operation Center)** 분야의 주요 논문을 읽고 정리하기 위한 공간이다.  
실습보다는 개념 이해와 사고 확장을 목표로 하며,  
로그 기반 이상탐지, SIEM 자동화, 지능형 관제 기술의 발전 흐름을 중심으로 다룬다.

---

## 왜 SOC인가

**Week 1-8 도메인 탐색 결과:**  
보안 컨설팅, OT/ICS, 클라우드 등 8개 분야의 대표 논문을 읽으며 나에게 맞는 분야를 탐색한 결과,  
**SOC(Security Operations Center)** 가 가장 적합하다고 판단했다.

**Week 9 이후:**  
SOC 관련 논문을 집중적으로 읽으며 **SOC가 무엇인지, 어떻게 운영되는지** 근본부터 이해한다.

---

## 목적

- 로그 기반 이상탐지(Log Anomaly Detection) 연구의 핵심 아이디어를 이해한다.  
- 관제 자동화 및 AI 기반 이상탐지 기술의 흐름을 파악한다.  
- SOC의 기술적 진화 방향을 논문 관점에서 체계적으로 정리한다.

---

## 논문 목록

- **DeepLog: Anomaly Detection and Diagnosis from System Logs** (CCS 2017)  
  [Paper Link](https://users.cs.utah.edu/~lifeifei/papers/deeplog.pdf)

- **Mining Invariants from Console Logs for System Problem Detection** (USENIX ATC 2010)  
  [Paper Link](https://www.usenix.org/legacy/events/atc10/tech/full_papers/Lou.pdf)

---

## 학습 원칙

- 논문 이해의 목적은 **암기가 아니라 응용**이다.
- 각 논문은 5일간 체계적으로 분석하며, **SOC 실무 적용 가능성**을 중심으로 정리한다.
- 단순 요약을 넘어, **"이 연구가 실제 SOC 운영에 어떻게 적용될 수 있는가"**에 집중한다.

---

> 이 폴더의 모든 내용은 논문을 통한 **지식 확장**을 목적으로 하며,  
> 실험 코드나 구현 내용은 포함하지 않는다.

---

# Research Review: Mining Invariants from Console Logs for System Problem Detection

> **Analyzed Date:** 2024.12.23  
> **Keywords:** Log_Invariants, Anomaly_Detection, Execution_Flow, Linear_Relationships, Rule_Mining  
> **Source:** USENIX ATC 2010 [Paper Link](https://www.usenix.org/legacy/events/atc10/tech/full_papers/Lou.pdf)

---

## Day 2 – Research Model, Hypotheses, and Methodology
*(불변성을 어떻게 자동으로 찾아내는가)*

### 1. 연구 모델 개요

이 논문의 핵심은 **4단계 파이프라인**으로 구성된다:

```
[비정형 로그] 
    ↓ (1) Log Parsing
[구조화 로그: 시그니처 + 파라미터]
    ↓ (2) Log Message Grouping
[메시지 카운트 벡터]
    ↓ (3) Invariant Mining
[불변성 집합]
    ↓ (4) Anomaly Detection
[이상 탐지 결과]
```

각 단계를 자세히 살펴보자.

---

### 2. 불변성의 수학적 표현

#### A. 선형 방정식으로서의 불변성

**핵심 아이디어:** 불변성은 로그 메시지 개수 간의 선형 방정식으로 표현된다.

m개의 로그 메시지 유형이 있을 때, 불변성은 다음과 같이 표현:

```
a₀ + a₁x₁ + a₂x₂ + ... + aₘxₘ = 0
```

여기서:
- `xⱼ`: j번째 로그 메시지 유형의 개수
- `θ = [a₀, a₁, ..., aₘ]ᵀ`: 불변성 벡터 (계수들)

**예시:** Day 1의 `c(B) = c(C) + c(D)` 는:
- 벡터 표현: `θ = [0, 0, 1, -1, -1, 0]ᵀ`
- 의미: B 메시지 1개 = C 메시지 1개 + D 메시지 1개

#### B. 행렬 형태로 확장

n개의 과거 로그 시퀀스가 있을 때, 메시지 카운트 행렬 X:

```
X = [1  x₁₁  x₁₂  ...  x₁ₘ]
    [1  x₂₁  x₂₂  ...  x₂ₘ]
    [⋮   ⋮    ⋮   ⋱    ⋮  ]
    [1  xₙ₁  xₙ₂  ...  xₙₘ]
```

모든 정상 로그가 불변성을 만족한다면:

```
Xθ = 0
```

**핵심 통찰:** 불변성 벡터 θ는 행렬 X의 **영공간(Null Space)** 에 속한다!

#### C. 불변성 공간 (Invariant Space)

| 개념 | 정의 | 의미 |
|------|------|------|
| **Row Space** | X의 행벡터들이 생성하는 공간 | 실제 관찰된 로그 패턴들 |
| **Null Space** | Xθ = 0을 만족하는 모든 θ의 공간 | 가능한 모든 불변성들 |
| **Invariant Space** | X의 Null Space | 프로그램의 불변성 공간 |

**중요:** 영공간의 모든 벡터가 불변성이지만, 의미 있는 불변성을 찾으려면 **희소성(Sparseness)** 과 **정수 제약(Integer Constraint)** 이 필요!

---

### 3. 연구 방법론: 4단계 파이프라인

### Step 1: 로그 파싱 (Log Parsing)

#### 목표
비정형 텍스트 로그를 구조화된 형태로 변환

**입력 예시:**
```
New job added to schedule, jobid = 8821, priority = 64
```

**출력 형태:**
```
Signature: "New job added to schedule, jobid=[], priority=[]"
Parameters: [8821, 64]
```

#### 변환 과정

| 요소 | 설명 | 추출 방법 |
|------|------|-----------|
| **Message Signature** | 로그 타입을 나타내는 상수 텍스트 | 같은 log-print 문에서 나온 메시지들의 공통 부분 |
| **Parameter Values** | 실행마다 변하는 변수 값들 | 숫자, ID 등 가변적인 부분 |
| **Timestamp** | 로그 발생 시간 | 로그 시작 부분의 시간 정보 |

**튜플 표현:**
```
(Timestamp, Signature, [Param1, Param2, ...])
```

**논문의 파싱 방법:**
- 소스 코드가 있으면: 코드 기반 파싱 (높은 정확도)
- 소스 코드 없으면: 자동 패턴 인식 알고리즘 [논문 저자의 이전 연구, 95% 정확도]

---

### Step 2: 로그 메시지 그룹핑 (Log Message Grouping)

#### 핵심 아이디어: Cogenetic Parameters (동원 파라미터)

**문제:** 같은 프로그램 변수가 여러 로그 문장에서 다른 파라미터로 나타날 수 있다.

**예시:**
```
Log A: "Request received, reqID = 12345"
Log B: "Processing request, requestID = 12345"
Log C: "Request completed, req = 12345"
```
→ 세 파라미터(reqID, requestID, req)는 실제로는 **같은 변수**!

#### Cogenetic Parameters 판별 알고리즘

**Algorithm 1: Log Parameter Grouping**

**Step 1:** 각 파라미터의 값 범위(Value Range) 계산
- 각 로그 묶음(log bunch)에서 파라미터의 모든 고유 값 추출
- 예: Pa의 값 범위 Vr(Pa) = {12345, 67890, ...}

**Step 2:** 두 파라미터가 동원인지 판별

두 파라미터 Pa와 Pb가 동원이려면:

| 조건 | 설명 | 이유 |
|------|------|------|
| **부분집합 관계** | 모든 로그 묶음에서 Vr(Pa) ⊆ Vr(Pb) 또는 반대 | 같은 변수면 값 범위가 겹침 |
| **충분한 값 개수** | min(\|Vr(Pa)\|, \|Vr(Pb)\|) ≥ 10 | 우연의 일치 방지 |
| **충분한 값 길이** | 각 값이 최소 3글자 이상 | 짧은 값(1, 2)은 우연히 겹칠 수 있음 |

**Step 3:** 동원 파라미터 그룹 형성
- Pa ≅ Pb 이고 Pa ≅ Pc 이면 → Pa, Pb, Pc는 모두 동원
- 전이적 관계(transitive)를 이용해 그룹 확장

**결과:** 각 그룹 = 하나의 프로그램 변수

#### 메시지 그룹 생성

동원 파라미터 그룹 A에 대해:
- A에 속한 파라미터를 포함하는 로그들 중
- **파라미터 값이 모두 같은** 로그들을 하나의 그룹으로 묶음

**예시:**
```
동원 그룹: {reqID, requestID, req}
값 = 12345인 로그들 → 그룹 1
값 = 67890인 로그들 → 그룹 2
```

각 그룹 = **하나의 실행 경로**(예: 특정 요청 처리 과정)

#### 메시지 카운트 벡터 생성

각 메시지 그룹에서:
- 각 메시지 타입(signature)이 몇 개 나타났는지 계산
- 벡터 형태로 표현

**예시:**
```
그룹 1: [시그니처A: 5개, 시그니처B: 5개, 시그니처C: 3개, 시그니처D: 2개]
→ 카운트 벡터: [5, 5, 3, 2]
```

이렇게 모든 그룹의 카운트 벡터를 모으면 → **행렬 X 완성**!

---

### Step 3: 불변성 마이닝 (Invariant Mining)

#### 목표
행렬 X로부터 **희소하고 정수 계수를 가진 불변성**을 자동으로 찾기

#### A. 왜 희소성(Sparseness)인가?

**문제:** 영공간의 모든 벡터가 불변성이지만, 대부분은 의미 없음

**예시:**
- 의미 있는 불변성: `c(A) = c(B) + c(C)` (3개 항만 포함)
- 의미 없는 불변성: `0.73c(A) + 1.42c(B) - 0.91c(C) + ... (수십 개 항)` 

**핵심 통찰:**
- 프로그램의 **기본 실행 구조**(순차, 분기, 합류)는 단순함
- 단순한 구조 = 적은 수의 로그 타입만 관련됨
- 따라서 기본 불변성은 **희소**(sparse)해야 함

**희소성 정의:**
- 영이 아닌 계수의 개수가 K_X 이하
- K_X = m + 1 - r (m: 메시지 타입 수, r: 불변성 공간 차원)
- 실제로 K_X는 보통 3~4 정도로 작음

#### B. 왜 정수 제약(Integer Constraint)인가?

**이유:**
1. **물리적 의미:** 순차/분기/합류 구조는 정수 비율로 표현됨
   - 1:1 관계 (순차): `c(A) = c(B)`
   - 1:2 관계 (복제): `c(A) = 2*c(B)`
   - 합 관계 (분기): `c(A) = c(B) + c(C)`

2. **해석 용이성:** 정수 계수는 사람이 이해하기 쉬움
   - 좋은 예: `[0, 1, -1, -1, 0]` → "B = C + D"
   - 나쁜 예: `[0.17, 0.73, -0.91, -1.22, 0.03]` → "???"

#### C. Compact Invariant Set (간결한 불변성 집합)

**중복성 문제:**
```
{c(A) = c(B), c(A) = c(E), c(E) = c(B)}
```
→ 세 번째는 앞의 두 개로부터 유도 가능 (중복!)

**Compact Set 정의:**
- 어떤 불변성도 나머지 불변성들의 선형 결합이 아님
- 최대 r개의 불변성만 포함 (r = 불변성 공간 차원)

**목표:** 
**가장 큰 간결한 희소 정수 불변성 집합** 찾기!

#### D. 불변성 탐색 알고리즘

**Challenge:** 희소 불변성 찾기는 NP-Hard 문제!

**전략 1: 영공간 추정 (SVD 사용)**

```
1. 행렬 X에 대해 SVD 수행: X = UΛVᵀ
2. 작은 특이값에 해당하는 오른쪽 특이벡터들 검증
3. 지지율(Support Ratio) 계산:
   - 지지율 = 불변성을 만족하는 메시지 그룹 비율
   - 98% 이상이면 유효한 불변성
4. 유효한 벡터들의 span = 불변성 공간
```

**전략 2: 가설 검증 프레임워크 (Hypothesis Testing)**

**핵심 아이디어:** 
"k개의 특정 메시지 타입만 관련된 불변성이 있는가?"를 체계적으로 검증

**Algorithm 2: Mining Invariants**

```
Input: 메시지 카운트 행렬 X (n × (m+1))
Output: 간결한 희소 정수 불변성 집합

1. SVD로 불변성 공간 차원 r 추정

2. Brute Force 탐색 (k = 1 ~ 5):
   For k = 1 to 5:
       For 모든 k개 메시지 타입 조합:
           2.1) 부분 행렬 X' 생성 (k개 열만)
           2.2) 후보 벡터 θ' = argmin ||X'θ'||₂
           2.3) θ'를 정수화 (l = 1, 2, 3 시도)
           2.4) 지지율 계산
           2.5) 지지율 ≥ 98%면 유효한 불변성 추가
   
   종료 조건:
   - r개의 독립 불변성을 찾음, 또는
   - k > (m - r + 1)

3. (Optional) Greedy 탐색 (k > 5):
   탐욕 알고리즘으로 추가 불변성 탐색
```

**정수화 과정 예시:**
```
1. θ' = [0, 0.33, -0.67, 0] (실수 후보)
2. 최소 비제로 계수 0.33을 1로 스케일: × 3
3. θ = [0, 1, -2, 0] (정수 불변성!)
4. 의미: "메시지2 개수 = 메시지3 개수 × 2"
```

#### E. 계산 복잡도 최적화

**문제:** 조합 폭발
- m개 메시지 타입에서 k개 선택: C(m, k)
- 예: m=28, k=4 → 20,475가지!

**최적화 기법들:**

| 기법 | 설명 | 효과 |
|------|------|------|
| **메시지 그룹핑** | 관련 있는 메시지만 함께 분석 | m 크기 대폭 감소 |
| **조기 종료** | r개 찾으면 중단 | 불필요한 탐색 회피 |
| **중복 건너뛰기** | 이미 찾은 불변성의 선형 결합은 탐색 안 함 | 탐색 공간 대폭 축소 |
| **SVD 대신 EVD** | XᵀX로 차원 축소 (m×m 행렬) | 대규모 데이터 처리 가능 |

**실제 효과 (Hadoop 로그):**
```
MapTask Attempt ID 메시지 그룹:
- 원래 탐색 공간: 24,157
- 최적화 후: 3,310 (86% 감소!)
```

---

### 4. 실무 도전과제 해결 방법

#### 도전과제 1: 노이즈와 비정상 로그

**문제:** 수집된 로그 중 일부는 실패나 노이즈 포함

**해결책:** 지지율(Support Ratio) 개념
- 98% 이상의 로그 그룹이 만족하면 유효한 불변성
- 2% 이하의 이상은 허용 (유연성)

#### 도전과제 2: 부분 로그 시퀀스

**문제:** 지속적으로 실행되는 시스템에서 로그를 중간에 잘라서 수집

**해결책:** 
- 파라미터 그룹핑으로 완전한 실행 경로만 분석
- 불완전한 그룹은 지지율 계산에서 자연스럽게 제외

#### 도전과제 3: 로그 인터리빙

**문제:** 여러 작업의 로그가 섞여있음

**해결책:**
- FSA(Finite State Automaton) 방법은 인터리빙에 취약
- 이 논문의 방법은 **메시지 개수만** 사용하므로 순서 무관!
- 인터리빙에 영향받지 않음

---

### 5. SOC 관점 인사이트

#### A. DeepLog과의 방법론 비교

| 항목 | DeepLog | Invariants Mining |
|------|---------|-------------------|
| **사전 지식 필요** | 없음 (end-to-end 학습) | 파라미터 그룹핑 필요 |
| **계산 복잡도** | O(학습 반복수 × 데이터 크기) | NP-Hard지만 최적화 가능 |
| **설명 가능성** | 없음 (블랙박스) | 명확한 선형 관계 |
| **인터리빙 대응** | 시퀀스 순서 중요 | 개수만 보므로 순서 무관 |

#### B. SOC 실무 적용 시사점

**언제 이 방법을 쓸 것인가:**

1. **시스템이 명확한 실행 흐름을 가질 때**
   - 예: 워크플로우 엔진, ETL 파이프라인
   - 비례: 웹 서버 로그 (요청-처리-응답)

2. **로그에 프로그램 변수(ID) 포함 시**
   - 예: 요청ID, 작업ID, 세션ID
   - 반례: 단순 에러 메시지만 있는 경우

3. **근본 원인 분석이 중요할 때**
   - SOC 티켓: "TaskTracker 시작 100, 종료 95"
   - → 즉시 5개 좀비 프로세스 문제로 인식

**실무 체크리스트:**
- [ ] 로그에 요청ID/작업ID 같은 식별자 포함되는가?
- [ ] 시스템 실행 흐름이 비교적 예측 가능한가?
- [ ] 분석가가 탐지 이유를 설명해야 하는가?
- [ ] 로그가 여러 작업에서 섞여 나오는가? (인터리빙)

4개 중 3개 이상 Yes → 이 방법 고려!

---

### 6. 개인 인사이트 (Personal Insight)

**Day 2를 읽고 느낀 점:**

**1. 수학적 우아함**
불변성을 "영공간의 벡터"로 정의한 것이 정말 깔끔하다. Xθ = 0 라는 하나의 방정식이 모든 것을 설명한다.

**2. 실용성과 이론의 균형**
- 이론: NP-Hard 문제라는 것을 명확히 인식
- 실용: 실제 시스템에서 m-r이 작다는 관찰로 해결 가능함을 증명

**3. Cogenetic Parameters의 독창성**
"같은 변수를 자동으로 찾기"는 정말 어려운 문제인데, 값 범위 비교라는 간단한 휴리스틱으로 해결. 이런 실용적 접근이 인상적이다.

**4. DeepLog 대비 장단점 명확화**

**장점:**
- 인터리빙 문제 자연스럽게 해결 (순서 무관)
- 설명 가능성 (SOC 분석가에게 핵심)
- 파라미터 기반 그룹핑으로 탐색 공간 축소

**단점:**
- 파라미터가 없는 로그에는 적용 불가
- 여전히 조합 최적화 문제의 근본적 어려움
- 비선형 관계는 못 찾음

**5. SOC 실무 적용 전략**

실제 SOC에서는:
1. **1차 필터:** 이 방법으로 명확한 불변성 위반 탐지
   - 예: "시작 100, 종료 95" → 즉시 대응
2. **2차 분석:** DeepLog으로 미묘한 패턴 이상 탐지
   - 예: 정상 범위지만 비정상 시퀀스
3. **하이브리드:** 불변성 위반 정보를 DeepLog 학습에 활용
   - 예: 불변성 위반한 로그는 negative sample로 사용

**다음 궁금증 (Day 3 Preview):**
Hadoop에 실제로 적용하면 어떤 불변성을 찾았을까? 탐지율과 오탐율은? 실제 버그를 잡아냈나?

---


