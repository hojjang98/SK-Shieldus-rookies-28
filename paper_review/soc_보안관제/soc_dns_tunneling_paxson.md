# Research Review: Practical Comprehensive Bounds on Surreptitious Communication Over DNS
> **Analyzed Date:** 2025.01.13 - 2025.01.17  
> **Keywords:** DNS Tunneling, Data Exfiltration, Information Theory, Upper Bound Detection, Enterprise Security  
> **Source:** USENIX Security Symposium, 2013, Pages 17-32  
> **Link:** https://www.usenix.org/conference/usenixsecurity13/technical-sessions/presentation/paxson

---

## Why This Paper?

### 선정 배경
**도메인 탐색 결과:**  
8주간 보안 컨설팅, OT/ICS, 클라우드 등 8개 도메인 논문을 읽은 결과, SOC가 나의 강점과 흥미에 가장 부합함을 확인. 이제부터는 SOC 전문성 심화를 위한 체계적 학습 단계.

**이 논문을 선택한 이유:**  
- 지금까지 로그 기반 탐지(DeepLog, Lou et al.), 네트워크 행위 분석(Beehive), provenance 기반 APT 탐지(UNICORN)를 공부했다면, 이제는 **네트워크 프로토콜 레벨의 데이터 유출 탐지**로 확장할 시점
- DNS는 거의 모든 네트워크에서 차단되지 않아 공격자들이 가장 선호하는 데이터 유출 채널이며, 실제 SOC에서 자주 마주치는 위협
- 머신러닝이나 딥러닝이 아닌 **정보 이론 기반**의 수학적으로 엄밀한 탐지 접근법 - 설명 가능성이 높아 SOC 분석가의 의사결정을 지원
- 2013년 논문이지만 230억 개의 실제 DNS 쿼리를 분석한 대규모 실증 연구로, 현재까지도 DNS 터널링 탐지 연구의 기준점

**학습 목표:**  
1. 정보 이론을 활용한 DNS 터널링의 정량적 탐지 방법론 이해
2. 정책 기반 상한선(upper bound) 설정을 통한 실용적 탐지 전략 학습
3. 오탐률과 탐지율 사이의 tradeoff를 조직의 보안 정책에 따라 조정하는 실무 적용 방안

---

## Day 1 – Research Context & Motivation
*(DNS를 통한 은밀한 통신의 수학적 한계를 찾아서)*

### 1. 연구 배경: DNS 터널링, 가장 은밀하고 강력한 데이터 유출 채널

**DNS의 양면성**

DNS는 인터넷의 핵심 인프라다. 거의 모든 네트워크 통신이 DNS 쿼리로 시작되며, 방화벽이나 프록시에서도 거의 차단하지 않는다. 이는 정상적인 인터넷 사용에 필수적이지만, 동시에 공격자에게는 완벽한 데이터 유출 채널이 된다.

2013년 당시 이미 Iodine, dns2tcp, OzymanDNS 같은 DNS 터널링 도구들이 공개되어 있었고, APT 공격에서 실제로 사용되고 있었다. 공격자는 DNS 쿼리의 서브도메인 부분에 데이터를 인코딩하여 외부로 유출하고, DNS 응답을 통해 C&C 명령을 받을 수 있었다.

**현실의 한계**

기존의 DNS 터널링 탐지 방법들은 크게 두 가지 문제를 가지고 있었다.

첫째, **시그니처 기반 탐지**의 한계다. 알려진 터널링 도구의 특징을 찾는 방식은 새로운 도구나 변형에 취약하다. 공격자가 도구를 약간만 수정해도 탐지를 우회할 수 있다.

둘째, **통계적 이상 탐지**의 모호함이다. "비정상적으로 긴 서브도메인", "높은 엔트로피" 같은 휴리스틱은 임계값 설정이 임의적이고, 왜 의심스러운지 명확한 근거를 제시하기 어렵다. SOC 분석가 입장에서는 "이 도메인이 왜 터널링인가?"에 대한 설득력 있는 답변이 필요하다.

**연구 문제의식**

이 논문이 답하려는 핵심 질문은 다음과 같다.

**"특정 도메인이 DNS를 통해 받을 수 있는 정보량의 상한선을 수학적으로 계산할 수 있는가? 그리고 이 상한선을 초과하는 통신을 탐지함으로써, 터널링 도구나 기법에 무관하게 모든 은밀한 통신을 포착할 수 있는가?"**

이는 "이 도메인이 의심스럽다"가 아니라 "이 도메인이 정보 이론적으로 불가능한 양의 정보를 받고 있다"는 수학적 증거를 제시하는 접근이다.

### 2. 핵심 개념

| 개념 | 정의 | SOC 맥락에서의 의미 |
|------|------|---------------------|
| **Surreptitious Communication** | 정상적인 프로토콜을 악용하여 탐지를 회피하면서 정보를 전달하는 은밀한 통신 | DNS 쿼리를 위장한 데이터 유출 또는 C&C 통신으로, 일반적인 네트워크 모니터링으로는 식별이 어려움 |
| **Upper Bound** | 특정 도메인이 DNS 쿼리를 통해 수신할 수 있는 정보량의 이론적 최대치 | 조직의 보안 정책에 따라 설정하는 임계값으로, 이를 초과하는 도메인을 자동으로 의심 대상으로 분류 |
| **Kolmogorov Complexity** | 문자열의 무작위성과 압축 불가능성을 측정하는 정보 이론의 개념 | DNS 쿼리에 포함된 서브도메인의 정보 밀도를 정량화하여, 정상 도메인과 터널링을 구분하는 수학적 기준 |
| **Query Entropy** | DNS 쿼리 패턴의 불확실성 정도 | 높은 엔트로피는 무작위에 가까운 데이터 인코딩을 의미하며, 터널링의 강력한 지표 |
| **Information Rate** | 단위 시간당 전송되는 정보량 | 일일 전송량 제한(예: 4KB/day)을 설정하여 비정상적으로 많은 데이터를 전송하는 도메인 탐지 |

### 3. 이론적 기반: 정보 이론을 이용한 탐지 프레임워크

```
[정상 DNS 쿼리]
www.google.com
mail.naver.com
→ 낮은 정보량 (예측 가능한 패턴)
→ Kolmogorov Complexity: 낮음

[DNS 터널링 쿼리]
a8f3b92c.attacker.com
x71k4p9w.attacker.com
→ 높은 정보량 (압축 불가능한 무작위)
→ Kolmogorov Complexity: 높음

[탐지 프레임워크]
1. 각 DNS 쿼리의 정보량 계산
2. 도메인별로 누적 정보량 집계
3. 정책 기반 상한선(Upper Bound)과 비교
4. 초과 시 의심 도메인으로 플래그

[정책 설정]
보안 우선 조직: 4KB/day → 높은 탐지율, 분석 부담 증가
편의 우선 조직: 100KB/day → 낮은 오탐률, 일부 터널링 누락 가능
```

**핵심 아이디어:**

정보 이론의 기본 원리는 간단하다. 정상적인 도메인 이름은 의미 있는 단어나 약어로 구성되어 압축이 가능하다. 반면 터널링에 사용되는 도메인은 인코딩된 데이터이므로 무작위에 가깝고 압축이 불가능하다. 이 차이를 Kolmogorov Complexity로 정량화하고, 도메인이 받을 수 있는 정보량의 상한선을 계산한다. 조직은 보안 정책에 따라 이 상한선을 설정하고(예: 하루 4KB), 이를 초과하는 도메인을 자동으로 탐지한다. 이는 특정 터널링 도구에 의존하지 않는 포괄적 탐지 방법이다.

### 4. 연구의 핵심 기여

**학술적 기여:**

- **정보 이론 기반의 엄밀한 탐지 프레임워크**: 기존의 휴리스틱이나 머신러닝이 아닌, 수학적으로 증명 가능한 상한선을 제시. DNS 쿼리의 정보량을 정량적으로 측정하는 방법론 확립
- **포괄성(Comprehensiveness)과 실용성의 균형**: 모든 형태의 DNS 터널링을 이론적으로 포착할 수 있으면서도, 실제 기업 환경에서 적용 가능한 정책 기반 접근 제시
- **대규모 실증 연구**: 230억 개의 실제 DNS 쿼리를 분석하여 이론의 실효성을 검증. 학술 연구와 실무 사이의 간극을 좁힘

**SOC 실무 기여:**

- **명확한 탐지 근거**: "의심스럽다"가 아니라 "정보 이론적으로 불가능한 통신"이라는 객관적 근거 제시. 경영진이나 법무팀에 설명하기 용이
- **정책 기반 조정 가능성**: 조직의 위험 감수 수준에 따라 탐지 임계값을 자유롭게 조정 가능. 금융기관은 4KB/day, 일반 기업은 20KB/day처럼 유연한 운영
- **실질적 분석 부담 감소**: 4KB/day 정책 기준으로 주당 1-2건의 조사만 필요. 오탐률을 크게 줄이면서도 실제 위협은 놓치지 않음
- **59개의 실제 터널 탐지**: 실험실이 아닌 프로덕션 네트워크에서 실제 공격 탐지 성공. 방법론의 실전 적용 가능성 입증

### 5. SOC 관점 인사이트

**실무 적용 가능성:**

이 연구가 SOC에 주는 가장 큰 가치는 **설명 가능성**이다. 머신러닝 기반 탐지는 높은 정확도를 보이지만 "왜 이것이 악성인가?"에 대한 답이 블랙박스 안에 갇혀 있다. 반면 정보 이론 기반 접근은 "이 도메인은 하루에 47KB의 정보를 받았는데, 우리 정책상 상한선은 4KB입니다"라는 명확한 근거를 제시한다.

또한 **정책 기반 조정**이 가능하다는 점이 실무적으로 매우 중요하다. 보안팀은 조직의 위험 감수 수준, 분석 인력 규모, 업무 특성에 따라 임계값을 설정할 수 있다. 이는 단순히 벤더가 제공하는 기본 설정을 사용하는 것보다 훨씬 유연한 운영을 가능하게 한다.

**기존 학습과의 연결:**

- **DeepLog와의 대조**: DeepLog는 로그 시퀀스의 패턴을 학습하지만, 이 논문은 각 쿼리의 정보 밀도를 계산한다. 두 접근은 상호 보완적이다
- **Beehive와의 연계**: Beehive는 내부 네트워크의 행위를 추적하고, 이 논문은 외부로의 데이터 유출을 탐지한다. 함께 사용하면 내부 → 외부 공격 경로 전체를 커버
- **UNICORN과의 차별점**: UNICORN은 provenance 그래프로 APT를 추적하지만, 이 논문은 프로토콜 레벨에서 데이터 유출 자체를 차단한다. 탐지 레이어가 다름

**현실적 고려사항:**

첫째, **DNS over HTTPS(DoH)의 등장**이다. 2013년 이후 DoH가 표준화되면서 DNS 쿼리가 암호화되기 시작했다. 이 논문의 방법론은 평문 DNS를 가정하므로, DoH 환경에서는 TLS 지문이나 흐름 기반 분석 같은 추가 기법이 필요하다.

둘째, **계산 비용**이다. 230억 개의 쿼리를 실시간으로 분석하려면 상당한 처리 능력이 필요하다. 대규모 조직에서는 분산 처리 아키텍처나 샘플링 기법을 고려해야 한다.

셋째, **정당한 고엔트로피 트래픽**이다. CDN, 로드밸런서, API 엔드포인트 등은 정상적으로도 무작위에 가까운 서브도메인을 사용할 수 있다. 이를 구분하기 위해서는 화이트리스트 관리가 필수적이다.

하지만 이러한 한계에도 불구하고, 이 논문이 제시한 **정보 이론 기반의 정량적 탐지**라는 철학은 여전히 유효하며, 현대의 DNS 보안 솔루션들이 참고하는 기준점이 되고 있다.

---

**Day 1을 읽고 느낀 점:**

DNS 터널링 탐지를 "의심스러운 패턴 찾기"가 아니라 "수학적으로 불가능한 통신 입증하기"로 접근한다는 발상이 인상적이다. 이는 단순히 탐지 정확도를 높이는 것을 넘어, SOC 분석가가 왜 이것이 위협인지 명확하게 설명할 수 있게 만든다.

특히 **정책 기반 상한선 설정**이라는 개념이 실무적으로 매우 유용해 보인다. 보안은 항상 tradeoff다. 100% 탐지를 추구하면 오탐으로 분석팀이 마비되고, 오탐을 줄이려면 실제 위협을 놓칠 수 있다. 이 논문은 조직이 스스로 이 균형점을 찾을 수 있는 수학적 도구를 제공한다.

다만 2013년과 2025년 사이에 DoH, DNS over TLS 같은 암호화 DNS가 보편화되면서 이 방법론의 적용 범위가 제한된 것은 아쉽다. Day 2에서 구체적인 알고리즘을 보면서 이를 현대적 환경에 어떻게 적응시킬 수 있을지 고민해봐야겠다.

**다음 궁금증 (Day 2 Preview):**

- Kolmogorov Complexity를 실제로 어떻게 근사 계산하는가?
- 도메인별 정보량 집계를 실시간으로 처리하는 구체적인 알고리즘은?
- 230억 개 쿼리를 분석하는 시스템 아키텍처는 어떻게 설계했는가?
- 쿼리 타입(A, AAAA, TXT 등)에 따라 정보량 계산이 어떻게 달라지는가?