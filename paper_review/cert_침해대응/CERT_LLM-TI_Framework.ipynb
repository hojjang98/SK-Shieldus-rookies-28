{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "348b10b8",
   "metadata": {},
   "source": [
    "# 📄 Advancing Autonomous Incident Response: Leveraging LLMs and Cyber Threat Intelligence  \n",
    "> arXiv 2025 | Tellache et al.  \n",
    "> [논문 링크](https://arxiv.org/abs/2508.10677)\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Day 1 – CERT & Incident Response의 현재 한계  \n",
    "\n",
    "---\n",
    "\n",
    "### 📌 연구 배경과 동기  \n",
    "- **CERT의 역할 한계**  \n",
    "  CERT(Computer Emergency Response Team)는 보안 사고 발생 시 탐지, 분석, 대응, 복구를 담당하는 핵심 조직이다.  \n",
    "  그러나 대부분의 프로세스가 여전히 **사람 중심의 수동 판단**에 의존하고 있어 속도·정확도 모두 제한적이다.  \n",
    "\n",
    "- **데이터 폭증 문제**  \n",
    "  현대 CERT는 하루 수십 GB 규모의 로그와 수백 건의 Threat Intelligence(TI) 피드를 분석해야 한다.  \n",
    "  이런 비정형 데이터들을 사람이 직접 맥락적으로 해석하는 것은 사실상 불가능하다.  \n",
    "\n",
    "- **핵심 문제의식**  \n",
    "  - CERT의 대응 절차는 여전히 “사건 단위”로 분절되어 있으며, **지식이 누적되지 않는다.**  \n",
    "  - Threat Intelligence는 수집되지만 **실시간 대응 프로세스와 연동되지 않는다.**  \n",
    "  - 결과적으로 “속도 병목(Bottleneck)”과 “지식 단절(Knowledge Gap)”이 발생한다.  \n",
    "\n",
    "<br>\n",
    "\n",
    "### 📌 핵심 아이디어  \n",
    "- 논문은 CERT의 대응 체계를 **LLM(Large Language Model)** 과 **Threat Intelligence**를 결합해 자동화하려는 새로운 방향을 제시한다.  \n",
    "- 핵심 구조는 다음과 같다.  \n",
    "  1. **로그 및 TI 입력 통합:** MISP, STIX/TAXII 포맷 데이터를 LLM 입력으로 변환  \n",
    "  2. **맥락 분석:** LLM이 사건 로그를 해석해 공격 시퀀스 및 IOC 관계를 추론  \n",
    "  3. **대응 제안:** SOAR(보안 오케스트레이션 자동화)와 연동하여 자동 대응 시나리오 생성  \n",
    "  4. **지식 피드백:** 결과를 TI 데이터베이스로 되돌려 학습 루프(Feedback Loop) 완성  \n",
    "\n",
    "> “LLM은 탐지 이후의 ‘분석–대응–지식화’ 단계를 자동화하는 CERT의 두뇌 역할을 수행할 수 있다.”\n",
    "\n",
    "<br>\n",
    "\n",
    "### 📌 주요 기여  \n",
    "1. **Threat Intelligence 기반 CERT 자동화 프레임워크 제안**  \n",
    "   - 로그, IoC, TI 데이터를 LLM 입력으로 통합하여 사건의 전후 관계를 추론하는 구조 제시.  \n",
    "2. **Human-in-the-loop 기반 설계**  \n",
    "   - LLM의 판단을 CERT 분석가가 검증함으로써 완전 자동화가 아닌 **“지능적 보조(Assisted Intelligence)”** 구조로 구성.  \n",
    "3. **운영 지식의 순환 체계화**  \n",
    "   - 사건별 분석 결과가 TI로 재귀적 업데이트되어, 조직 차원의 지식 성장을 유도.  \n",
    "\n",
    "<br>\n",
    "\n",
    "### 📌 핵심 인사이트  \n",
    "- 기존 CERT는 단일 사건 대응에 머물렀지만, 본 논문은 **“사건 간 학습(Inter-incident Learning)”**을 핵심 목표로 삼는다.  \n",
    "- LLM은 단순한 자동화 엔진이 아니라, **보안 지식의 연결자(Knowledge Connector)** 로 작동한다.  \n",
    "- “탐지 이후의 인공지능”이라는 새로운 역할 정의를 제시함으로써, AI가 SOC를 넘어 CERT의 두뇌 역할로 확장되는 첫 사례를 보여준다.  \n",
    "\n",
    "<br>\n",
    "\n",
    "### 🧠 개인적 해석  \n",
    "- DeepLog가 로그 시퀀스를 통해 **탐지 자동화**의 가능성을 열었다면, 이 논문은 **대응 자동화**의 시대를 여는 출발점이라 볼 수 있다.  \n",
    "- 특히 LLM을 단순 텍스트 생성기가 아닌 **사고 분석 엔진(Analytical Reasoner)** 으로 활용했다는 점에서 실무적 의미가 크다.  \n",
    "- 결국 CERT의 본질은 ‘사건을 해결하는 조직’이 아니라, **사건으로부터 학습하는 조직**이며,  \n",
    "  이 논문은 그 학습을 “AI로 가속화”하는 방법을 제시한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6a25cc",
   "metadata": {},
   "source": [
    "## ✅ Day 2 – Proposed Framework Architecture  \n",
    "\n",
    "---\n",
    "\n",
    "### 📌 1️⃣ 개요 (Overview)\n",
    "\n",
    "본 논문은 LLM과 Threat Intelligence(TI)를 결합해 **CERT의 사고 대응 프로세스를 자동화**하는  \n",
    "새로운 아키텍처를 제안한다.  \n",
    "\n",
    "> 핵심 목표:  \n",
    "> **“Threat Data → LLM 분석 → SOAR 대응 → TI 피드백”**의 순환 루프를 통해 **지속적 학습형 CERT 시스템(Self-Improving CERT)** 구축  \n",
    "\n",
    "---\n",
    "\n",
    "### 🏗️ 2️⃣ 전체 구조 (System Design)\n",
    "\n",
    "시스템은 총 4개의 핵심 모듈로 구성된다.  \n",
    "\n",
    "| 계층 | 구성요소 | 역할 |\n",
    "|------|-----------|------|\n",
    "| **Data Ingestion Layer** | MISP Connector, STIX/TAXII Parser | 로그·IoC·Threat Feed를 표준 포맷으로 수집 및 정규화 |\n",
    "| **Reasoning Layer (LLM Core)** | Domain-Tuned LLM 모델 | 사건 로그 분석, 공격 시퀀스 추론, 대응 전략 생성 |\n",
    "| **Action Layer (SOAR Interface)** | Orchestrator, Response Script Engine | LLM 출력을 SOAR 플랫폼에 전달해 자동 대응 실행 |\n",
    "| **Knowledge Layer** | Threat DB, Feedback Module | 대응 결과를 TI 데이터베이스로 재귀 반영하여 지식 갱신 |\n",
    "\n",
    "> 💡 LLM은 단순한 언어 모델이 아니라, **사건 맥락(Contextual Reasoner)** 로서 CERT의 중추 역할을 수행한다.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧩 3️⃣ 핵심 구성요소 세부 설명\n",
    "\n",
    "#### (1) Data Ingestion & Normalization  \n",
    "- 다양한 소스(MISP, Elastic Logs, EDR Feeds 등)에서 데이터를 수집.  \n",
    "- STIX/TAXII 표준에 맞춰 LLM 입력용 JSON 스키마로 변환.  \n",
    "- 로그의 시맨틱 정보(공격자 행동, IOC, MITRE ATT&CK Mapping)를 자동 태깅.\n",
    "\n",
    "#### (2) LLM Reasoning Module  \n",
    "- 사전 학습된 LLM을 보안 도메인에 튜닝(Threat Ontology + Incident Playbook 기반 Fine-tuning).  \n",
    "- 기능:  \n",
    "  1. 공격 단계 식별 (Initial Access → Execution → Exfiltration)  \n",
    "  2. 행동 간 상관관계 분석  \n",
    "  3. 대응 조치 (Containment / Eradication / Recovery) 제안  \n",
    "- Human-in-the-Loop 구조로 CERT 분석가의 검증을 통과해야 SOAR에 전달됨.\n",
    "\n",
    "#### (3) SOAR Integration Module  \n",
    "- LLM 결과를 Python Action Script 혹은 API Call 형태로 SOAR에 전달.  \n",
    "- 예시 대응: IP 차단, 격리 명령, 포렌식 로그 수집 요청 등.  \n",
    "- 성공/실패 로그는 Knowledge Layer로 피드백.\n",
    "\n",
    "#### (4) Knowledge Feedback Loop  \n",
    "- 대응 결과를 Threat DB(MISP Instance)에 자동 기록.  \n",
    "- LLM은 이전 대응 사례를 참조해 **지속적 학습(Continuous Learning)** 수행.  \n",
    "- 이렇게 사건 지식이 누적되어 CERT 조직의 집단 지능이 형성됨.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔁 4️⃣ 데이터 흐름 요약 (End-to-End Flow)\n",
    "\n",
    "1. **로그 입력:** 보안 시스템 → Data Ingestion Layer  \n",
    "2. **맥락 해석:** LLM Reasoning Layer에서 공격 패턴 추론  \n",
    "3. **대응 결정:** SOAR Interface가 적절한 대응 시나리오 선택  \n",
    "4. **행동 실행:** 자동 스크립트 혹은 분석가 승인 후 조치 시행  \n",
    "5. **지식 피드백:** 결과 및 새로운 IOC가 Threat DB로 반영  \n",
    "\n",
    "> 🔁 이 루프를 통해 CERT는 사건마다 조금씩 더 똑똑해지는 지속 학습형 시스템으로 진화한다.\n",
    "\n",
    "---\n",
    "\n",
    "### 📌 5️⃣ 핵심 인사이트  \n",
    "\n",
    "- LLM 도입의 핵심은 **속도 개선**이 아니라 **지식 전이(Knowledge Transfer)** 에 있다.  \n",
    "- 과거 사건 경험이 TI → LLM → SOAR 로 순환하며 **조직 기억(Organizational Memory)** 을 형성한다.  \n",
    "- 이는 단순 자동화 플랫폼이 아닌 **“지능형 사이버 보안 에이전트”** 로의 진화 기반이다.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 개인적 해석  \n",
    "\n",
    "- 이 구조는 결국 “인간의 결정을 빠르게 확장하는 지식 자동화 엔진”이다.  \n",
    "- Threat Intelligence와 LLM을 단일 루프에 통합했다는 점은 SOC → CERT → TI 전 과정의 연결성을 의미한다.  \n",
    "- 앞으로 이 모델이 **SOC 탐지 → CERT 대응 → TI 학습** 을 하나의 지능형 에코시스템으로 통합할 가능성을 보여준다.  \n",
    "- Day 3에서는 이 아키텍처를 기반으로 한 **LLM Reasoning Mechanism 및 Prompt Engineering 전략**을 분석할 예정이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c639468f",
   "metadata": {},
   "source": [
    "## ✅ Day 3 – LLM Reasoning Mechanism & Prompt Engineering  \n",
    "\n",
    "---\n",
    "\n",
    "### 📌 1️⃣ LLM Reasoning 개요  \n",
    "\n",
    "본 논문은 CERT 자동화의 핵심으로 **LLM Reasoning Module**을 정의한다.  \n",
    "LLM은 단순한 텍스트 요약기가 아니라,  \n",
    "보안 이벤트의 **맥락적 이해(Contextual Reasoning)** 를 수행하는 분석 엔진으로 활용된다.  \n",
    "\n",
    "> “모델이 단어를 예측하는 것이 아니라, 행동의 의미를 추론한다.”  \n",
    "\n",
    "이 모듈은 보안 이벤트 로그와 Threat Intelligence 데이터를 입력으로 받아 공격 단계, 의도, 상관관계를 추론하고 적절한 대응 플랜을 생성한다.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 2️⃣ Reasoning Process (추론 과정)  \n",
    "\n",
    "논문은 LLM Reasoning 을 3단계 프로세스로 설명한다.  \n",
    "\n",
    "| 단계 | 역할 | 입력/출력 |\n",
    "|------|------|------------|\n",
    "| ① Event Parsing & Contextualization | 로그에서 핵심 엔터티 추출 (시간, IP, IOC, 프로세스명) 및 위협 맥락 설정 | 입력: Syslog / MISP 데이터 → 출력: Structured Prompt |\n",
    "| ② Threat Correlation Reasoning | IoC, TTP 간 관계를 추론해 공격 시퀀스 재구성 | 입력: Normalized Prompt → 출력: Attack Graph 설명 |\n",
    "| ③ Response Planning | 공격 단계별 대응 전략을 생성 (Containment, Eradication, Recovery) | 출력: SOAR Action Command or Playbook Draft |\n",
    "\n",
    "> LLM의 출력은 바로 SOAR에 전달되지 않으며, **CERT 분석가 검증 (Human-in-the-Loop)** 을 거쳐 승인 후 실행된다.\n",
    "\n",
    "---\n",
    "\n",
    "### 💬 3️⃣ Prompt Engineering 전략  \n",
    "\n",
    "LLM 이 위협 데이터를 정확히 이해하도록 하기 위해 논문에서는 세 가지 Prompt 기법을 적용하였다.  \n",
    "\n",
    "#### (1) Structured Prompt Format  \n",
    "- Threat 데이터를 **JSON 스키마 형태**로 입력  \n",
    "- 각 필드에 명확한 의미를 부여 (ex: “attack_vector”, “affected_host”, “impact_score”)  \n",
    "- 이를 통해 LLM이 자유 서술형 이해가 아닌 **객체 단위 추론(Object-based Reasoning)** 을 수행하도록 유도  \n",
    "\n",
    "#### (2) Context-Aware Prompt Chaining  \n",
    "- 하나의 대형 Prompt가 아닌, **다단계 Prompt 연쇄**로 처리  \n",
    "  - ① 이벤트 요약 → ② 의심 행동 분석 → ③ 공격 단계 추론 → ④ 대응 제안  \n",
    "- 단계별 결과가 다음 Prompt의 입력으로 연결되어 **Chain-of-Reasoning 흐름** 구성  \n",
    "\n",
    "#### (3) Threat Schema Alignment  \n",
    "- MITRE ATT&CK 및 CVE 데이터베이스 태그를 활용하여  \n",
    " LLM 출력 형식을 기존 보안 분류체계와 정렬(Alignment).  \n",
    "- 이 과정이 LLM의 **보안 온톨로지 일관성(Threat Ontology Consistency)** 을 보장함.  \n",
    "\n",
    "---\n",
    "\n",
    "### 🔐 4️⃣ Human-in-the-Loop 검증 구조  \n",
    "\n",
    "| 단계 | 역할 |\n",
    "|------|------|\n",
    "| LLM Output 검토 | CERT 분석가가 LLM의 추론 결과를 점검하고 오탐/과잉대응을 차단 |\n",
    "| Feedback 수집 | 분석가 평가를 Knowledge Layer에 기록 |\n",
    "| 모델 재학습 | 이전 피드백을 LLM Fine-tuning 에 반영해 지속적 개선 |\n",
    "\n",
    "> 이 검증 루프를 통해 LLM 은 시간이 지날수록 조직의 정책·환경에 맞게 진화한다.\n",
    "\n",
    "---\n",
    "\n",
    "### 📈 5️⃣ 결과 및 의의  \n",
    "\n",
    "- Prompt 기반 추론을 통해 LLM 이 “공격 단계 식별 정확도 및 대응 일관성” 면에서 기존 규칙 기반 시스템보다 향상됨을 보고함.  \n",
    "- LLM이 Threat Intelligence 데이터를 활용해 **공격자 의도와 패턴을 맥락적으로 해석**할 수 있음을 보여줌.  \n",
    "- Human-in-the-Loop 구조로 “완전 자동화” 가 아닌 “지능적 보조” 형태의 실용적 접근을 유지.  \n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 개인적 해석  \n",
    "\n",
    "- 이 파트는 “AI가 보안을 이해하는 방법”을 정의한 부분이다.  \n",
    "- Prompt Flow 를 단순 질문-응답이 아닌 **사고 사슬(Reasoning Chain)** 으로 설계했다는 점이 인상적이다.  \n",
    "- CERT 분석가의 경험 지식이 LLM 피드백 루프를 통해 모델 성능으로 전환된다는 점에서, 이 논문은 “AI 보안 조직의 지능화” 방향을 실증적으로 보여준다.  \n",
    "- Day 4에서는 이 Reasoning 모듈의 성능 평가와 실험 결과(Experiments & Evaluation)를 분석할 예정이다."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
