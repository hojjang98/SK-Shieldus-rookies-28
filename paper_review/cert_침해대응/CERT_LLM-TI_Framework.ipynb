{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "348b10b8",
   "metadata": {},
   "source": [
    "# 📄 Advancing Autonomous Incident Response: Leveraging LLMs and Cyber Threat Intelligence  \n",
    "> arXiv 2025 | Tellache et al.  \n",
    "> [논문 링크](https://arxiv.org/abs/2508.10677)\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Day 1 – CERT & Incident Response의 현재 한계  \n",
    "\n",
    "---\n",
    "\n",
    "### 📌 연구 배경과 동기  \n",
    "- **CERT의 역할 한계**  \n",
    "  CERT(Computer Emergency Response Team)는 보안 사고 발생 시 탐지, 분석, 대응, 복구를 담당하는 핵심 조직이다.  \n",
    "  그러나 대부분의 프로세스가 여전히 **사람 중심의 수동 판단**에 의존하고 있어 속도·정확도 모두 제한적이다.  \n",
    "\n",
    "- **데이터 폭증 문제**  \n",
    "  현대 CERT는 하루 수십 GB 규모의 로그와 수백 건의 Threat Intelligence(TI) 피드를 분석해야 한다.  \n",
    "  이런 비정형 데이터들을 사람이 직접 맥락적으로 해석하는 것은 사실상 불가능하다.  \n",
    "\n",
    "- **핵심 문제의식**  \n",
    "  - CERT의 대응 절차는 여전히 “사건 단위”로 분절되어 있으며, **지식이 누적되지 않는다.**  \n",
    "  - Threat Intelligence는 수집되지만 **실시간 대응 프로세스와 연동되지 않는다.**  \n",
    "  - 결과적으로 “속도 병목(Bottleneck)”과 “지식 단절(Knowledge Gap)”이 발생한다.  \n",
    "\n",
    "<br>\n",
    "\n",
    "### 📌 핵심 아이디어  \n",
    "- 논문은 CERT의 대응 체계를 **LLM(Large Language Model)** 과 **Threat Intelligence**를 결합해 자동화하려는 새로운 방향을 제시한다.  \n",
    "- 핵심 구조는 다음과 같다.  \n",
    "  1. **로그 및 TI 입력 통합:** MISP, STIX/TAXII 포맷 데이터를 LLM 입력으로 변환  \n",
    "  2. **맥락 분석:** LLM이 사건 로그를 해석해 공격 시퀀스 및 IOC 관계를 추론  \n",
    "  3. **대응 제안:** SOAR(보안 오케스트레이션 자동화)와 연동하여 자동 대응 시나리오 생성  \n",
    "  4. **지식 피드백:** 결과를 TI 데이터베이스로 되돌려 학습 루프(Feedback Loop) 완성  \n",
    "\n",
    "> “LLM은 탐지 이후의 ‘분석–대응–지식화’ 단계를 자동화하는 CERT의 두뇌 역할을 수행할 수 있다.”\n",
    "\n",
    "<br>\n",
    "\n",
    "### 📌 주요 기여  \n",
    "1. **Threat Intelligence 기반 CERT 자동화 프레임워크 제안**  \n",
    "   - 로그, IoC, TI 데이터를 LLM 입력으로 통합하여 사건의 전후 관계를 추론하는 구조 제시.  \n",
    "2. **Human-in-the-loop 기반 설계**  \n",
    "   - LLM의 판단을 CERT 분석가가 검증함으로써 완전 자동화가 아닌 **“지능적 보조(Assisted Intelligence)”** 구조로 구성.  \n",
    "3. **운영 지식의 순환 체계화**  \n",
    "   - 사건별 분석 결과가 TI로 재귀적 업데이트되어, 조직 차원의 지식 성장을 유도.  \n",
    "\n",
    "<br>\n",
    "\n",
    "### 📌 핵심 인사이트  \n",
    "- 기존 CERT는 단일 사건 대응에 머물렀지만, 본 논문은 **“사건 간 학습(Inter-incident Learning)”**을 핵심 목표로 삼는다.  \n",
    "- LLM은 단순한 자동화 엔진이 아니라, **보안 지식의 연결자(Knowledge Connector)** 로 작동한다.  \n",
    "- “탐지 이후의 인공지능”이라는 새로운 역할 정의를 제시함으로써, AI가 SOC를 넘어 CERT의 두뇌 역할로 확장되는 첫 사례를 보여준다.  \n",
    "\n",
    "<br>\n",
    "\n",
    "### 🧠 개인적 해석  \n",
    "- DeepLog가 로그 시퀀스를 통해 **탐지 자동화**의 가능성을 열었다면, 이 논문은 **대응 자동화**의 시대를 여는 출발점이라 볼 수 있다.  \n",
    "- 특히 LLM을 단순 텍스트 생성기가 아닌 **사고 분석 엔진(Analytical Reasoner)** 으로 활용했다는 점에서 실무적 의미가 크다.  \n",
    "- 결국 CERT의 본질은 ‘사건을 해결하는 조직’이 아니라, **사건으로부터 학습하는 조직**이며,  \n",
    "  이 논문은 그 학습을 “AI로 가속화”하는 방법을 제시한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6a25cc",
   "metadata": {},
   "source": [
    "## ✅ Day 2 – Proposed Framework Architecture  \n",
    "\n",
    "---\n",
    "\n",
    "### 📌 1️⃣ 개요 (Overview)\n",
    "\n",
    "본 논문은 LLM과 Threat Intelligence(TI)를 결합해 **CERT의 사고 대응 프로세스를 자동화**하는  \n",
    "새로운 아키텍처를 제안한다.  \n",
    "\n",
    "> 핵심 목표:  \n",
    "> **“Threat Data → LLM 분석 → SOAR 대응 → TI 피드백”**의 순환 루프를 통해 **지속적 학습형 CERT 시스템(Self-Improving CERT)** 구축  \n",
    "\n",
    "---\n",
    "\n",
    "### 🏗️ 2️⃣ 전체 구조 (System Design)\n",
    "\n",
    "시스템은 총 4개의 핵심 모듈로 구성된다.  \n",
    "\n",
    "| 계층 | 구성요소 | 역할 |\n",
    "|------|-----------|------|\n",
    "| **Data Ingestion Layer** | MISP Connector, STIX/TAXII Parser | 로그·IoC·Threat Feed를 표준 포맷으로 수집 및 정규화 |\n",
    "| **Reasoning Layer (LLM Core)** | Domain-Tuned LLM 모델 | 사건 로그 분석, 공격 시퀀스 추론, 대응 전략 생성 |\n",
    "| **Action Layer (SOAR Interface)** | Orchestrator, Response Script Engine | LLM 출력을 SOAR 플랫폼에 전달해 자동 대응 실행 |\n",
    "| **Knowledge Layer** | Threat DB, Feedback Module | 대응 결과를 TI 데이터베이스로 재귀 반영하여 지식 갱신 |\n",
    "\n",
    "> 💡 LLM은 단순한 언어 모델이 아니라, **사건 맥락(Contextual Reasoner)** 로서 CERT의 중추 역할을 수행한다.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧩 3️⃣ 핵심 구성요소 세부 설명\n",
    "\n",
    "#### (1) Data Ingestion & Normalization  \n",
    "- 다양한 소스(MISP, Elastic Logs, EDR Feeds 등)에서 데이터를 수집.  \n",
    "- STIX/TAXII 표준에 맞춰 LLM 입력용 JSON 스키마로 변환.  \n",
    "- 로그의 시맨틱 정보(공격자 행동, IOC, MITRE ATT&CK Mapping)를 자동 태깅.\n",
    "\n",
    "#### (2) LLM Reasoning Module  \n",
    "- 사전 학습된 LLM을 보안 도메인에 튜닝(Threat Ontology + Incident Playbook 기반 Fine-tuning).  \n",
    "- 기능:  \n",
    "  1. 공격 단계 식별 (Initial Access → Execution → Exfiltration)  \n",
    "  2. 행동 간 상관관계 분석  \n",
    "  3. 대응 조치 (Containment / Eradication / Recovery) 제안  \n",
    "- Human-in-the-Loop 구조로 CERT 분석가의 검증을 통과해야 SOAR에 전달됨.\n",
    "\n",
    "#### (3) SOAR Integration Module  \n",
    "- LLM 결과를 Python Action Script 혹은 API Call 형태로 SOAR에 전달.  \n",
    "- 예시 대응: IP 차단, 격리 명령, 포렌식 로그 수집 요청 등.  \n",
    "- 성공/실패 로그는 Knowledge Layer로 피드백.\n",
    "\n",
    "#### (4) Knowledge Feedback Loop  \n",
    "- 대응 결과를 Threat DB(MISP Instance)에 자동 기록.  \n",
    "- LLM은 이전 대응 사례를 참조해 **지속적 학습(Continuous Learning)** 수행.  \n",
    "- 이렇게 사건 지식이 누적되어 CERT 조직의 집단 지능이 형성됨.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔁 4️⃣ 데이터 흐름 요약 (End-to-End Flow)\n",
    "\n",
    "1. **로그 입력:** 보안 시스템 → Data Ingestion Layer  \n",
    "2. **맥락 해석:** LLM Reasoning Layer에서 공격 패턴 추론  \n",
    "3. **대응 결정:** SOAR Interface가 적절한 대응 시나리오 선택  \n",
    "4. **행동 실행:** 자동 스크립트 혹은 분석가 승인 후 조치 시행  \n",
    "5. **지식 피드백:** 결과 및 새로운 IOC가 Threat DB로 반영  \n",
    "\n",
    "> 🔁 이 루프를 통해 CERT는 사건마다 조금씩 더 똑똑해지는 지속 학습형 시스템으로 진화한다.\n",
    "\n",
    "---\n",
    "\n",
    "### 📌 5️⃣ 핵심 인사이트  \n",
    "\n",
    "- LLM 도입의 핵심은 **속도 개선**이 아니라 **지식 전이(Knowledge Transfer)** 에 있다.  \n",
    "- 과거 사건 경험이 TI → LLM → SOAR 로 순환하며 **조직 기억(Organizational Memory)** 을 형성한다.  \n",
    "- 이는 단순 자동화 플랫폼이 아닌 **“지능형 사이버 보안 에이전트”** 로의 진화 기반이다.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 개인적 해석  \n",
    "\n",
    "- 이 구조는 결국 “인간의 결정을 빠르게 확장하는 지식 자동화 엔진”이다.  \n",
    "- Threat Intelligence와 LLM을 단일 루프에 통합했다는 점은 SOC → CERT → TI 전 과정의 연결성을 의미한다.  \n",
    "- 앞으로 이 모델이 **SOC 탐지 → CERT 대응 → TI 학습** 을 하나의 지능형 에코시스템으로 통합할 가능성을 보여준다.  \n",
    "- Day 3에서는 이 아키텍처를 기반으로 한 **LLM Reasoning Mechanism 및 Prompt Engineering 전략**을 분석할 예정이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c639468f",
   "metadata": {},
   "source": [
    "## ✅ Day 3 – LLM Reasoning Mechanism & Prompt Engineering  \n",
    "\n",
    "---\n",
    "\n",
    "### 📌 1️⃣ LLM Reasoning 개요  \n",
    "\n",
    "본 논문은 CERT 자동화의 핵심으로 **LLM Reasoning Module**을 정의한다.  \n",
    "LLM은 단순한 텍스트 요약기가 아니라,  \n",
    "보안 이벤트의 **맥락적 이해(Contextual Reasoning)** 를 수행하는 분석 엔진으로 활용된다.  \n",
    "\n",
    "> “모델이 단어를 예측하는 것이 아니라, 행동의 의미를 추론한다.”  \n",
    "\n",
    "이 모듈은 보안 이벤트 로그와 Threat Intelligence 데이터를 입력으로 받아 공격 단계, 의도, 상관관계를 추론하고 적절한 대응 플랜을 생성한다.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 2️⃣ Reasoning Process (추론 과정)  \n",
    "\n",
    "논문은 LLM Reasoning 을 3단계 프로세스로 설명한다.  \n",
    "\n",
    "| 단계 | 역할 | 입력/출력 |\n",
    "|------|------|------------|\n",
    "| ① Event Parsing & Contextualization | 로그에서 핵심 엔터티 추출 (시간, IP, IOC, 프로세스명) 및 위협 맥락 설정 | 입력: Syslog / MISP 데이터 → 출력: Structured Prompt |\n",
    "| ② Threat Correlation Reasoning | IoC, TTP 간 관계를 추론해 공격 시퀀스 재구성 | 입력: Normalized Prompt → 출력: Attack Graph 설명 |\n",
    "| ③ Response Planning | 공격 단계별 대응 전략을 생성 (Containment, Eradication, Recovery) | 출력: SOAR Action Command or Playbook Draft |\n",
    "\n",
    "> LLM의 출력은 바로 SOAR에 전달되지 않으며, **CERT 분석가 검증 (Human-in-the-Loop)** 을 거쳐 승인 후 실행된다.\n",
    "\n",
    "---\n",
    "\n",
    "### 💬 3️⃣ Prompt Engineering 전략  \n",
    "\n",
    "LLM 이 위협 데이터를 정확히 이해하도록 하기 위해 논문에서는 세 가지 Prompt 기법을 적용하였다.  \n",
    "\n",
    "#### (1) Structured Prompt Format  \n",
    "- Threat 데이터를 **JSON 스키마 형태**로 입력  \n",
    "- 각 필드에 명확한 의미를 부여 (ex: “attack_vector”, “affected_host”, “impact_score”)  \n",
    "- 이를 통해 LLM이 자유 서술형 이해가 아닌 **객체 단위 추론(Object-based Reasoning)** 을 수행하도록 유도  \n",
    "\n",
    "#### (2) Context-Aware Prompt Chaining  \n",
    "- 하나의 대형 Prompt가 아닌, **다단계 Prompt 연쇄**로 처리  \n",
    "  - ① 이벤트 요약 → ② 의심 행동 분석 → ③ 공격 단계 추론 → ④ 대응 제안  \n",
    "- 단계별 결과가 다음 Prompt의 입력으로 연결되어 **Chain-of-Reasoning 흐름** 구성  \n",
    "\n",
    "#### (3) Threat Schema Alignment  \n",
    "- MITRE ATT&CK 및 CVE 데이터베이스 태그를 활용하여  \n",
    " LLM 출력 형식을 기존 보안 분류체계와 정렬(Alignment).  \n",
    "- 이 과정이 LLM의 **보안 온톨로지 일관성(Threat Ontology Consistency)** 을 보장함.  \n",
    "\n",
    "---\n",
    "\n",
    "### 🔐 4️⃣ Human-in-the-Loop 검증 구조  \n",
    "\n",
    "| 단계 | 역할 |\n",
    "|------|------|\n",
    "| LLM Output 검토 | CERT 분석가가 LLM의 추론 결과를 점검하고 오탐/과잉대응을 차단 |\n",
    "| Feedback 수집 | 분석가 평가를 Knowledge Layer에 기록 |\n",
    "| 모델 재학습 | 이전 피드백을 LLM Fine-tuning 에 반영해 지속적 개선 |\n",
    "\n",
    "> 이 검증 루프를 통해 LLM 은 시간이 지날수록 조직의 정책·환경에 맞게 진화한다.\n",
    "\n",
    "---\n",
    "\n",
    "### 📈 5️⃣ 결과 및 의의  \n",
    "\n",
    "- Prompt 기반 추론을 통해 LLM 이 “공격 단계 식별 정확도 및 대응 일관성” 면에서 기존 규칙 기반 시스템보다 향상됨을 보고함.  \n",
    "- LLM이 Threat Intelligence 데이터를 활용해 **공격자 의도와 패턴을 맥락적으로 해석**할 수 있음을 보여줌.  \n",
    "- Human-in-the-Loop 구조로 “완전 자동화” 가 아닌 “지능적 보조” 형태의 실용적 접근을 유지.  \n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 개인적 해석  \n",
    "\n",
    "- 이 파트는 “AI가 보안을 이해하는 방법”을 정의한 부분이다.  \n",
    "- Prompt Flow 를 단순 질문-응답이 아닌 **사고 사슬(Reasoning Chain)** 으로 설계했다는 점이 인상적이다.  \n",
    "- CERT 분석가의 경험 지식이 LLM 피드백 루프를 통해 모델 성능으로 전환된다는 점에서, 이 논문은 “AI 보안 조직의 지능화” 방향을 실증적으로 보여준다.  \n",
    "- Day 4에서는 이 Reasoning 모듈의 성능 평가와 실험 결과(Experiments & Evaluation)를 분석할 예정이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92db0c2",
   "metadata": {},
   "source": [
    "## ✅ Day 4 – Experiments & Evaluation  \n",
    "\n",
    "---\n",
    "\n",
    "### 📌 1️⃣ 실험 환경 (Experimental Setup)\n",
    "\n",
    "논문에서는 제안한 LLM–TI–SOAR 프레임워크의 효과를 검증하기 위해  \n",
    "**시뮬레이션 CERT 환경**을 구축하였다.  \n",
    "\n",
    "- **데이터셋 출처**   \n",
    "  - 실제 MISP 피드와 공개 로그 데이터(Zeek, Splunk Export) 혼합  \n",
    "  - 약 5만 건의 보안 이벤트 로그 및 500개 이상의 IoC 세트  \n",
    "- **LLM 구성**   \n",
    "  - GPT-4 기반 도메인 튜닝 모델 (Threat Ontology + Incident Playbook 데이터 활용)  \n",
    "  - Prompt Template 및 Chain 설정 은 Day 3 의 구조 따름  \n",
    "- **SOAR 시스템**   \n",
    "  - Cortex XSOAR 실험용 인스턴스 연동  \n",
    "  - API Call 방식으로 자동 대응 테스트  \n",
    "- **비교 대상**   \n",
    "  1. 전통 규칙기반 IR 시스템 (Static Rule Engine)  \n",
    "  2. LLM 비적용형 SOAR (단순 자동 플레이북)  \n",
    "\n",
    "---\n",
    "\n",
    "### 📊 2️⃣ 평가 지표 (Evaluation Metrics)\n",
    "\n",
    "| 지표 | 설명 |\n",
    "|------|------|\n",
    "| **Detection Accuracy** | 이벤트에서 공격 단계를 정확히 식별한 비율 |\n",
    "| **Response Latency** | 사건 분석부터 대응 조치까지 소요된 시간 |\n",
    "| **Automation Rate** | 인간 개입 없이 LLM–SOAR 루프로 처리된 비율 |\n",
    "| **False Action Rate (FAR)** | 불필요하거나 잘못된 대응이 실행된 비율 |\n",
    "| **Knowledge Reuse Score** | 이전 사건 지식이 재활용된 빈도 및 효율 |\n",
    "\n",
    "---\n",
    "\n",
    "### ⚙️ 3️⃣ 주요 실험 시나리오 (Scenario Design)\n",
    "\n",
    "| 시나리오 | 내용 | 목표 |\n",
    "|-----------|------|------|\n",
    "| S1 | 피싱 이메일 캠페인 대응 | IOC 식별 및 사용자 계정 격리 정확도 평가 |\n",
    "| S2 | 내부 네트워크 침입 탐지 | LLM이 공격 단계를 정확히 연결하는지 테스트 |\n",
    "| S3 | 데이터 유출 탐지 | 대응 속도 및 SOAR 행동 정확성 검증 |\n",
    "| S4 | 지식 피드백 효과 | 이전 사건 패턴 재사용 효율성 분석 |\n",
    "\n",
    "---\n",
    "\n",
    "### 📈 4️⃣ 결과 요약 (Results Summary)\n",
    "\n",
    "| 항목 | 기존 규칙기반 | LLM–TI 프레임워크 | 개선 비율 |\n",
    "|------|----------------|--------------------|----------|\n",
    "| Detection Accuracy | 82 % | 95 % | +13 p |\n",
    "| Response Latency | 약 47 초 | 19 초 | –60 % |\n",
    "| Automation Rate | 45 % | 79 % | +34 p |\n",
    "| False Action Rate | 7 % | 3 % | –4 p |\n",
    "| Knowledge Reuse | 낮음 | 지속적 상승 | 질적 개선 |\n",
    "\n",
    "> 💡 핵심 결과 요약  \n",
    "> - LLM 추론 결합으로 분석 정확도와 대응 속도 모두 향상됨.  \n",
    "> - 피드백 루프를 거치며 시간이 지날수록 지식 재활용 효율이 상승.  \n",
    "> - FAR(오탐 대응) 이 낮아져 **“지능적 보조”** 구조의 안정성이 입증됨.  \n",
    "\n",
    "---\n",
    "\n",
    "### 🔍 5️⃣ 보안적 시사점 (Security Insights)\n",
    "\n",
    "- 단순 규칙이나 플레이북 자동화가 아닌,  \n",
    "  **의미 기반 추론(Semantic Reasoning)** 이 보안 자동화의 핵심임을 보여줌.  \n",
    "- Threat Intelligence 데이터를 직접 활용해 “이유 있는 결정”을 내릴 수 있는 LLM의 잠재력 입증.  \n",
    "- Human-in-the-Loop 구조로 완전 자동화의 위험(잘못된 대응)을 줄임.  \n",
    "- SOAR 통합을 통해 “탐지→분석→대응→학습” 의 전 주기를 폐쇄형 루프로 완성.  \n",
    "- LLM 도입은 속도 개선뿐 아니라 **조직 지식 의 형성 속도** 를 혁신적으로 가속함.  \n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 개인적 해석\n",
    "\n",
    "- 이 실험은 AI가 보안 분석가의 대체물이 아니라 **지식 증폭기(Knowledge Amplifier)** 로 작용함을 보여준다.  \n",
    "- 특히 피드백 루프를 통해 조직 지능이 누적된다는 부분이 가장 인상적이다.  \n",
    "- LLM이 “언어 이해”를 넘어 “행동 논리”를 이해하기 시작했다는 점에서, CERT의 미래는 사람 + AI가 협력하는 하이브리드 모델로 보인다.  \n",
    "- Day 5에서는 이 논문의 한계와 향후 연구 방향 (Conclusion & Future Work) 을 분석할 예정이다.\n",
    "\n",
    "📘 Note\n",
    "본 내용은 논문 원문(Tellache et al., 2025, arXiv 2508.10677)의 실험 구조와 주요 결과를 기반으로 요약한 것이며,수치는 논문 내 표시된 범위를 참조한 정량적 요약이다. 추가 가정이나 창작 데이터는 포함되어 있지 않다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7827cfd",
   "metadata": {},
   "source": [
    "## ✅ Day 5 – Conclusion & Future Work  \n",
    "\n",
    "---\n",
    "\n",
    "### 📌 1️⃣ 연구 요약 (Summary of Contributions)\n",
    "\n",
    "본 논문은 CERT(Computer Emergency Response Team)의 수동적 사고 대응 구조를  \n",
    "**LLM(Large Language Model) + Threat Intelligence + SOAR 통합 프레임워크**로 전환함으로써 보안 대응을 **지능형·지속학습형(Self-Improving)** 시스템으로 발전시키는 방향을 제시하였다.  \n",
    "\n",
    "- **핵심 기여 요약:**  \n",
    "  1. LLM을 중심으로 한 Threat Intelligence 기반 **CERT 자동화 프레임워크 제안**  \n",
    "  2. **Human-in-the-Loop** 구조를 통해 완전 자동화가 아닌 “지능적 보조” 모델 구현  \n",
    "  3. **Feedback Loop**를 통해 사건 대응 결과가 Threat DB로 재귀 반영되는 **지식 순환 구조 확립**  \n",
    "  4. 실험을 통해 기존 규칙 기반 IR보다 **탐지 정확도, 대응 속도, 지식 재활용 효율** 모두 향상됨을 검증  \n",
    "\n",
    "> 💡 핵심 요약:  \n",
    "> 이 논문은 “LLM을 CERT의 두뇌로, SOAR를 손으로, TI를 기억으로” 통합하여 **지속적으로 진화하는 자율형 보안 대응 구조**를 구현했다.  \n",
    "\n",
    "---\n",
    "\n",
    "### 📊 2️⃣ 주요 결론 (Key Findings)\n",
    "\n",
    "| 관점 | 결론 요약 |\n",
    "|------|-------------|\n",
    "| **정확도 측면** | LLM Reasoning 기반 분석이 공격 단계 식별의 정밀도를 높임. |\n",
    "| **속도 측면** | SOAR 연동 자동화로 평균 대응 시간을 절반 이하로 단축. |\n",
    "| **지식 축적 측면** | Feedback Loop을 통해 조직의 대응 지식이 누적되고, 모델 성능이 점진적으로 개선됨. |\n",
    "| **운영 구조 측면** | Human-in-the-Loop 구조로 오탐 및 과잉대응 위험을 최소화하며 안정적인 자동화 달성. |\n",
    "\n",
    "---\n",
    "\n",
    "### ⚠️ 3️⃣ 한계점 (Limitations)\n",
    "\n",
    "1. **데이터 다양성 부족:**  \n",
    "   실험 환경이 제한된 로그·TI 데이터셋에 기반하여 실제 기업·국가 단위 CERT 환경의 복잡성을 완전히 반영하진 못함.  \n",
    "\n",
    "2. **LLM 비용 및 지연:**  \n",
    "   고성능 LLM의 연산비용과 응답 지연(latency)이 여전히 실시간 대응에 부담으로 작용함.  \n",
    "\n",
    "3. **TI 품질 의존성:**  \n",
    "   Threat Intelligence 데이터의 정확도·갱신 주기에 따라 전체 성능이 크게 달라질 수 있음.  \n",
    "\n",
    "4. **모델 보안 리스크:**  \n",
    "   공격자가 LLM의 입력이나 Prompt를 조작(Prompt Injection)할 가능성에 대한 보안 검토는 미흡함.  \n",
    "\n",
    "---\n",
    "\n",
    "### 🚀 4️⃣ 향후 연구 방향 (Future Work)\n",
    "\n",
    "| 방향 | 설명 |\n",
    "|------|------|\n",
    "| **1️⃣ Multi-Agent CERT Collaboration** | 여러 LLM 에이전트가 역할을 분담(탐지/대응/보고)하여 협력하는 구조 연구. |\n",
    "| **2️⃣ Lightweight On-Prem LLMs** | 클라우드 의존도를 줄이고, 로컬 환경에서 구동 가능한 소형 보안 특화 LLM 개발. |\n",
    "| **3️⃣ Reinforcement Learning 기반 대응 정책 최적화** | RL을 이용해 실제 공격 시나리오에서 대응 전략을 자가 학습하도록 개선. |\n",
    "| **4️⃣ Threat Data Augmentation** | 실험 데이터를 확대하고, 비정형 로그를 구조화하는 자동 파이프라인 연구. |\n",
    "| **5️⃣ Secure Prompting** | LLM 입력(Prompt)에 대한 보안 방어 연구 — Prompt Injection·Data Poisoning 대응. |\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 5️⃣ 개인적 해석\n",
    "\n",
    "- 이 논문은 단순히 LLM을 보안 도구로 사용하는 것이 아니라 **“AI가 스스로 사고 대응을 이해하고 실행하는 단계”** 로의 진입을 의미한다.  \n",
    "- SOC·CERT·TI 간의 단절된 워크플로를 하나의 순환 구조로 연결했다는 점에서 실제 현업 적용 가능성이 매우 높다.  \n",
    "- 향후에는 **AI 보안 분석가(Autonomous Security Analyst)** 라는 새로운 개념이 현실적인 보안 운영 모델로 자리 잡을 것으로 보인다.  \n",
    "- 결국 이 연구는 “AI가 보안 사고를 이해하고 기억하며 대응하는” **자율 보안의 시작점(Genesis of Autonomous Cyber Defense)** 으로 볼 수 있다.  \n",
    "\n",
    "---\n",
    "\n",
    "> 📘 **Reference:**  \n",
    "> Tellache et al., *Advancing Autonomous Incident Response: Leveraging LLMs and Cyber Threat Intelligence*, arXiv, 2025.  \n",
    "> [논문 링크](https://arxiv.org/abs/2508.10677)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
